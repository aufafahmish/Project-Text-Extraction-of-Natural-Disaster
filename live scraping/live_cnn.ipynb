{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting live scrape for today's articles...\n",
      "Scraping articles for date: 2025/02/23\n",
      "Processing Article: Polisi Jamin Keamanan Band Sukatani Manggung di Tegal Hari Ini\n",
      "Skipping article (no matching keywords): Polisi Jamin Keamanan Band Sukatani Manggung di Tegal Hari Ini\n",
      "Processing Article: Belum Ikut Retret, Kepala Daerah PDIP Standby di Magelang\n",
      "Skipping article (no matching keywords): Belum Ikut Retret, Kepala Daerah PDIP Standby di Magelang\n",
      "Processing Article: Bupati Purbalingga Tawarkan Vokalis Sukatani Jadi Guru Lagi\n",
      "Skipping article (no matching keywords): Bupati Purbalingga Tawarkan Vokalis Sukatani Jadi Guru Lagi\n",
      "Processing Article: Korban Bom Bali Takut Bantuan Negara via LPSK Kena Efisiensi Anggaran\n",
      "Skipping article (no matching keywords): Korban Bom Bali Takut Bantuan Negara via LPSK Kena Efisiensi Anggaran\n",
      "Processing Article: 3 Koper Wabup Deli Serdang Rusak di Bandara Usai Pulang Pelantikan\n",
      "Skipping article (no matching keywords): 3 Koper Wabup Deli Serdang Rusak di Bandara Usai Pulang Pelantikan\n",
      "Processing Article: Gunung Semeru Erupsi Sabtu Malam, Tinggi Letusan 700 Meter\n",
      "Processing Article: Mendagri Tito Semangat Ikut Senam Pagi di Retreat Mageleng\n",
      "Skipping article (no matching keywords): Mendagri Tito Semangat Ikut Senam Pagi di Retreat Mageleng\n",
      "Processing Article: Iwakum Wanti-wanti Pelaku Doxing Wartawan Bisa Dijerat Pidana\n",
      "Skipping article (no matching keywords): Iwakum Wanti-wanti Pelaku Doxing Wartawan Bisa Dijerat Pidana\n",
      "Processing Article: 1.524 Rumah Warga di Bandar Lampung Terendam Banjir, Ada 3 Warga Tewas\n",
      "Processing Article: Masinton: Kepala Daerah PDIP Siap Ikut Retret, 1-2 Hari Ini Gabung\n",
      "Skipping article (no matching keywords): Masinton: Kepala Daerah PDIP Siap Ikut Retret, 1-2 Hari Ini Gabung\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cnnindonesia.com/nasional/20250223...</td>\n",
       "      <td>23/02/2025</td>\n",
       "      <td>Gunung Semeru Erupsi Sabtu Malam, Tinggi Letus...</td>\n",
       "      <td>Gunung Semeru yang terletak di Lumajang dan Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cnnindonesia.com/nasional/20250222...</td>\n",
       "      <td>22/02/2025</td>\n",
       "      <td>1.524 Rumah Warga di Bandar Lampung Terendam B...</td>\n",
       "      <td>Setidaknya sebanyak 1.524 rumah warga di sembi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL        Date  \\\n",
       "0  https://www.cnnindonesia.com/nasional/20250223...  23/02/2025   \n",
       "1  https://www.cnnindonesia.com/nasional/20250222...  22/02/2025   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Gunung Semeru Erupsi Sabtu Malam, Tinggi Letus...   \n",
       "1  1.524 Rumah Warga di Bandar Lampung Terendam B...   \n",
       "\n",
       "                                             Content  \n",
       "0  Gunung Semeru yang terletak di Lumajang dan Ma...  \n",
       "1  Setidaknya sebanyak 1.524 rumah warga di sembi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to cnn_live_scrape_today.xlsx.\n",
      "Waiting for 2 minutes before the next scrape...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def scrape_cnn_today(keywords):\n",
    "    \"\"\"\n",
    "    Scrapes CNN Indonesia articles for today's date and returns a list of articles.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.0.0\"\n",
    "    }\n",
    "    keyword_pattern = re.compile(\"|\".join(keywords), re.IGNORECASE)\n",
    "    today_date = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "    base_url = f\"https://www.cnnindonesia.com/peristiwa/indeks/18?\"\n",
    "\n",
    "    news_list = []\n",
    "\n",
    "    print(f\"Scraping articles for date: {today_date}\")\n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching page: {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all(\"article\", class_=\"flex-grow\")\n",
    "\n",
    "    for article in articles:\n",
    "        link_tag = article.find(\"a\", href=True)\n",
    "        link = link_tag['href'] if link_tag else None\n",
    "        title_tag = article.find(\"h2\", class_=\"text-cnn_black_light dark:text-white mb-2 inline leading-normal text-xl group-hover:text-cnn_red\")\n",
    "        title = title_tag.text.strip() if title_tag else \"No title\"\n",
    "\n",
    "        # Skip jika link tidak valid\n",
    "        if not link or not link.startswith(\"http\"):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing Article: {title}\")\n",
    "\n",
    "        try:\n",
    "            article_response = requests.get(link, headers=headers)\n",
    "            article_response.raise_for_status()\n",
    "            article_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
    "\n",
    "            # Ambil tanggal\n",
    "            date_element = article_soup.find(\"div\", class_=\"text-cnn_grey text-sm mb-4\")\n",
    "            date = date_element.text.strip() if date_element else \"No date found\"\n",
    "            bulan_mapping = {\n",
    "                \"Jan\": \"Jan\", \"Feb\": \"Feb\", \"Mar\": \"Mar\", \"Apr\": \"Apr\", \"Mei\": \"May\",\n",
    "                \"Jun\": \"Jun\", \"Jul\": \"Jul\", \"Agu\": \"Aug\", \"Sep\": \"Sep\", \"Okt\": \"Oct\",\n",
    "                \"Nov\": \"Nov\", \"Des\": \"Dec\"\n",
    "            }\n",
    "            # Cari pola tanggal dalam teks\n",
    "            match = re.search(r'(\\d{1,2}) (\\w{3}) (\\d{4})', date)\n",
    "            if match:\n",
    "                day, month, year = match.groups()\n",
    "                month = bulan_mapping.get(month, month)  # Ubah bulan jika ada di mapping\n",
    "\n",
    "                # Konversi format dari \"15 Agu 2024\" menjadi \"15/08/2024\"\n",
    "                date_obj = datetime.strptime(f\"{day} {month} {year}\", \"%d %b %Y\")\n",
    "                date = date_obj.strftime(\"%d/%m/%Y\")  # Format akhir: \"15/08/2024\"\n",
    "\n",
    "            # Ambil konten\n",
    "            content_element = article_soup.find(\"div\", class_=\"detail-text text-cnn_black text-sm grow min-w-0\")\n",
    "            if content_element:\n",
    "                # Hapus elemen <div class=\"paradetail\"> (iklan)\n",
    "                for ad_div in content_element.find_all(\"div\", class_=\"paradetail\"):\n",
    "                    ad_div.decompose()\n",
    "                \n",
    "                content_paragraphs = content_element.find_all(\"p\")\n",
    "                content = \"\"\n",
    "                for p in content_paragraphs:\n",
    "                    p_text = \"\"\n",
    "\n",
    "                    # Memproses elemen di dalam <p>, termasuk <span> dan <a>\n",
    "                    for element in p.children:\n",
    "                        if element.name == \"span\" or element.name == \"a\":\n",
    "                            p_text += \" \" + element.get_text(strip=True) + \" \"\n",
    "                        elif element.name is None:\n",
    "                            p_text += element.strip() + \" \"\n",
    "                    \n",
    "                    content += p_text.strip() + \" \"\n",
    "                content = re.sub(r'\\s+', ' ', content).strip()\n",
    "            else:\n",
    "                content = \"No content found\"\n",
    "\n",
    "            # Filter berdasarkan kata kunci\n",
    "            if keyword_pattern.search(title) or keyword_pattern.search(content):\n",
    "                news_list.append({\n",
    "                    \"URL\": link,\n",
    "                    \"Date\": date,\n",
    "                    \"Title\": title,\n",
    "                    \"Content\": content\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping article (no matching keywords): {title}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching article {link}: {e}\")\n",
    "    \n",
    "    return news_list\n",
    "\n",
    "def live_scrape_cnn_today():\n",
    "    \"\"\"\n",
    "    Runs CNN scraping for today every 2 minutes, displays, and saves the articles to Excel.\n",
    "    \"\"\"\n",
    "    keywords = [\n",
    "        r\"\\berupsi\\b\", r\"\\bgunung meletus\\b\", r\"\\btanah longsor\\b\", r\"\\blongsor\\b\",\n",
    "        r\"\\bbanjir\\b\", r\"\\bbanjir bandang\\b\", r\"\\btsunami\\b\",\n",
    "        r\"\\bgempa\\b\", r\"\\bgempa bumi\\b\", r\"\\bbadai\\b\", r\"\\bputing beliung\\b\", r\"\\bangin kencang\\b\",\n",
    "        r\"\\bkekeringan\\b\", r\"\\bkemarau panjang\\b\", r\"\\bhujan es\\b\", r\"\\bgelombang panas\\b\",\n",
    "        r\"\\bcuaca ekstrem\\b\", r\"\\bgelombang ekstrem\\b\", r\"\\bgemuruh laut\\b\",\n",
    "        r\"\\bkebakaran hutan\\b\", r\"\\bkebakaran lahan\\b\", r\"\\bkarhutla\\b\", r\"\\bapi\\b\"\n",
    "    ]\n",
    "    \n",
    "    all_articles = pd.DataFrame(columns=[\"URL\", \"Date\", \"Title\", \"Content\"])\n",
    "    file_name = \"cnn_live_scrape_today.xlsx\"\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nStarting live scrape for today's articles...\")\n",
    "        articles = scrape_cnn_today(keywords)\n",
    "        \n",
    "        if articles:\n",
    "            new_df = pd.DataFrame(articles)\n",
    "\n",
    "            # Gabungkan dengan data sebelumnya\n",
    "            all_articles = pd.concat([all_articles, new_df], ignore_index=True).drop_duplicates(subset=[\"URL\"])\n",
    "\n",
    "            # Tampilkan data terbaru\n",
    "            display(all_articles)\n",
    "\n",
    "            # Simpan ke Excel\n",
    "            all_articles.to_excel(file_name, index=False)\n",
    "            print(f\"Saved to {file_name}.\")\n",
    "        else:\n",
    "            print(\"No new articles found.\")\n",
    "\n",
    "        # Tunggu 2 menit sebelum scrape berikutnya\n",
    "        print(\"Waiting for 2 minutes before the next scrape...\\n\")\n",
    "        time.sleep(120)\n",
    "\n",
    "# Jalankan live scrape\n",
    "live_scrape_cnn_today()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
